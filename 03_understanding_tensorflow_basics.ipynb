{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Tensorflow Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly speaking, working with TensorFlow involves two main phases: (1) constructing a graph and (2) executing it. Let’s jump into our first example and create something very basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Constant nodes \n",
    "a, b = tf.constant(5), tf.constant(10)\n",
    "\n",
    "## Nodes perform arithmetic operations\n",
    "d, e= tf.multiply(a, b), tf.subtract(b, a)\n",
    "\n",
    "# logical not\n",
    "z = ~(a > b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = 50\n",
      "outs = 50\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "outs = sess.run(d)\n",
    "sess.close()\n",
    "\n",
    "print 'outs = %d' % outs\n",
    "\n",
    "# Equivalent form\n",
    "with tf.Session() as sess:\n",
    "    print 'outs = %d' % sess.run(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3-1\n",
    "### A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, b = tf.constant(10), tf.constant(20)\n",
    "d = a + b\n",
    "c = a * b\n",
    "f = c + d\n",
    "e = d - c\n",
    "g = f / e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 200, 230, -170, -2)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(d), sess.run(c), sess.run(f), sess.run(e), sess.run(g))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, b = tf.constant(10, dtype=tf.float32), tf.constant(20, dtype=tf.float32)\n",
    "\n",
    "c = a * b\n",
    "d = tf.sin(c)\n",
    "e = b / d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-22.9017\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(e))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing and Managing Our Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_g = tf.get_default_graph()\n",
    "g = tf.Graph() ## Creates new graph \n",
    "k = tf.constant(5)\n",
    "k.graph is g # Node 'k' is in the default graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **with** statement can also be used to start a session without having to explicitly\n",
    "close it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    k = tf.constant(123)\n",
    "    print k.graph is g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.0, 20.0, 200.0, -0.87329727, -22.901709, 230] <type 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    fetches = [a, b, c, d, e, f]\n",
    "    outs = sess.run(fetches)\n",
    "print outs, type(outs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes Are Operations, Edges Are Tensor Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source operations** are operations\n",
    "that create data, usually without using any previously processed inputs. With these\n",
    "operations we can create scalars, as we already encountered with the ``tf.constant()``\n",
    "method, as well as arrays and other types of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicit Vs Implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float64, tf.float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.constant(4.0, dtype=tf.float64)\n",
    "d = tf.constant(4.0)\n",
    "\n",
    "c.dtype, d.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "<dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1,2,3], name='x', dtype=tf.float32)\n",
    "print(x.dtype)\n",
    "x = tf.cast(x, tf.int64)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Arrays and Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([Dimension(2), Dimension(3)]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(10).shape, tf.constant([[1,2,3], [3,5,6]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1,)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}'.format(tf.constant([10]).get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]\n"
     ]
    }
   ],
   "source": [
    "## Evenly Spaced values from 1.0 to 10.0\n",
    "\n",
    "rand = tf.linspace(1.0, 10.0, 10)\n",
    "sess = tf.Session()\n",
    "print(sess.run(rand))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "fill = tf.fill((10,10), 1)\n",
    "print(sess.run(fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.zeros((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.40343952,  0.86059642],\n",
       "       [ 1.47445035,  1.12114859]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.random_normal((2,2), 1, 0.5)) ## args: mean, stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.71181309,  0.43175948],\n",
       "       [ 0.69321871,  0.35593814]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.truncated_normal((2,2), 1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.46346688,  8.87239838],\n",
       "       [ 9.19039917,  0.01349807]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.random_uniform((2,2), 0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant([[1,2,3],\n",
    "                 [4,5,6]])\n",
    "x = tf.constant([[1],[0],[1]])\n",
    "print(A.get_shape())\n",
    "print(x.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "b = tf.matmul(A, x)\n",
    "print(b.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternate way of expanding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3, 1)\n",
      "(2, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4],\n",
       "       [10]], dtype=int32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.constant([[1,2,3],\n",
    "                 [4,5,6]])\n",
    "x = tf.constant([1,0,1]) ## Shape (3,)\n",
    "x = tf.expand_dims(x, 1) ## Shape (3, 1)\n",
    "\n",
    "print(A.get_shape())\n",
    "print(x.get_shape())\n",
    "b = tf.matmul(A, x)\n",
    "print(b.get_shape())\n",
    "\n",
    "sess.run(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposing Matix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4],\n",
       "       [3, 5]], dtype=int32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,2, 3],\n",
    "                [3,4,5]])\n",
    "transpose = tf.transpose(a)\n",
    "print(a.get_shape())\n",
    "print(transpose.get_shape())\n",
    "sess.run(transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Names\n",
    "Objects residing within the same graph cannot have the same name\n",
    "—TensorFlow forbids it. As a consequence, it will automatically\n",
    "add an underscore and a number to distinguish the two. Of course,\n",
    "both objects can have the same name when they are associated with\n",
    "different graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'c:0', u'c_1:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Graph().as_default(): ## Creating a new graph\n",
    "    c1 = tf.constant(4, dtype=tf.float32, name='c')\n",
    "    c2 = tf.constant(5, dtype=tf.float32, name='c')\n",
    "c1.name, c2.name ## name arg + index of tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Scope\n",
    "Sometimes when dealing with a large, complicated graph, we would like to create\n",
    "some node grouping to make it easier to follow and manage. For that we can hier‐\n",
    "archically group nodes together by name.\n",
    "\n",
    "* Very useful when divding graphs into subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'c:0', u'prefix/0:0', u'prefix/k:0')\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    c1 = tf.constant(4, name='c')\n",
    "    with tf.name_scope('prefix'):\n",
    "        c2 = tf.constant(45, name='0')\n",
    "        c3 = tf.constant(45, name='k')\n",
    "print(c1.name, c2.name, c3.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables, Placeholder and Simple Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre run \n",
      "<tf.Variable 'var_4:0' shape=(1, 5) dtype=float32_ref>\n",
      "\n",
      "Post run: \n",
      "[[ 0.59393317  1.04858518 -1.14982152 -0.41200474  0.829445  ]]\n"
     ]
    }
   ],
   "source": [
    "init_val = tf.random_normal((1,5), 0, 1) ## Rand tensor generator\n",
    "var = tf.Variable(init_val, name='var') ## init_val: default value\n",
    "print('Pre run \\n{}\\n'.format(var))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    post_var = sess.run(var)\n",
    "\n",
    "print('Post run: \\n{}'.format(post_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholders\n",
    "Placeholders can be thought of as empty Variables that will be filled with data later on. We use them by first constructing our graph and only when it is exe‐\n",
    "cuted feeding them with the input data.\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ph = tf.placeholder(tf.float32, (None, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs 3.52244710922\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_data = np.random.randn(5,10)\n",
    "w_data = np.random.randn(10,1)\n",
    "\n",
    "x_data.shape, w_data.shape\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=(5,10))\n",
    "    w = tf.placeholder(tf.float32, shape=(10,1))\n",
    "    b = tf.fill((5,1), -1) ## Fill with -1\n",
    "    xw = tf.matmul(x, w)\n",
    "    \n",
    "    xwb = xw + tf.cast(b, tf.float32)\n",
    "    s = tf.reduce_max(xwb)\n",
    "    with tf.Session() as sess:\n",
    "        outs = sess.run(s, feed_dict={x: x_data, w: w_data})\n",
    "        \n",
    "print('outs {}'.format(outs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(xi) = wTxi + b\n",
    "\n",
    "yi = f(xi) + ε"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Variables and placeholder\n",
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y_true = tf.placeholder(tf.float32, shape=None)\n",
    "w = tf.Variable([[0,0,0]], dtype=tf.float32, name='weights')\n",
    "b = tf.Variable(0, dtype=tf.float32, name='bias')\n",
    "\n",
    "y_pred = tf.matmul(w, tf.transpose(x)) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a loss function\n",
    "The most commonly used loss is **MSE**(Mean Squared Error) and **cross entropy** especially for categorical data.\n",
    "* Cross entropy is a measure of similarity between two distributions. Since the classifi‐cation models used in deep learning typically output probabilities for each class, we can compare the true class (distribution p) with the probabilities of each class given by the model (distribution q). The more similar the two distributions, the smaller our cross entropy will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y_true - y_pred)) ## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "loss_cross_entropy = tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The gradient descent optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient descent algorithms work well on highly complicated network architectures and therefore are suitable for a wide variety of problems. More specifically,\n",
    "recent advances make it possible to compute these gradients by utilizing massively\n",
    "parallel systems, so the approach scales well with dimensionality (though it can still\n",
    "be painfully time-consuming for large real-world problems). While convergence to\n",
    "the global minimum is guaranteed for convex functions, for nonconvex problems\n",
    "(which are essentially all problems in the world of deep learning) they can get stuck\n",
    "in local minima. In practice, this is often good enough, as is evidenced by the huge\n",
    "success of the field of deep learning.\n",
    "\n",
    "###  Why need sampling\n",
    "It becomes very slow and is intractable when the dataset requires more memory\n",
    "\n",
    "A more popular technique is the **stochastic gradient descent (SGD)**, where instead of\n",
    "feeding the entire dataset to the algorithm for the computation of each step, a subset\n",
    "of the data is sampled sequentially. The number of samples ranges from one sample at\n",
    "a time to a few hundred, but the most common sizes are between around 50 to\n",
    "around 500 (usually referred to as mini-batches)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_data = np.random.randn(2000, 3)\n",
    "w_real = [0.3, 0.5, 0.1]\n",
    "b_real = -0.2\n",
    "\n",
    "noise = np.random.randn(1,2000) * .1\n",
    "y_data = np.matmul(w_real, x_data.T) + b_real + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [array([[ 0.28649634,  0.46323544,  0.09672525]], dtype=float32), -0.18146181])\n",
      "(5, [array([[ 0.29955566,  0.50041938,  0.09742881]], dtype=float32), -0.2047427])\n",
      "(10, [array([[ 0.29955569,  0.50041944,  0.09742881]], dtype=float32), -0.20474274])\n"
     ]
    }
   ],
   "source": [
    "NUM_STEPS = 10\n",
    "g = tf.Graph()\n",
    "wb_ = []\n",
    "\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "    y_true = tf.placeholder(tf.float32, shape=None)\n",
    "    \n",
    "    with tf.name_scope('inference') as scope:\n",
    "        w = tf.Variable([[0,0,0]], dtype=tf.float32, name='weights')\n",
    "        b = tf.Variable(0, dtype=tf.float32, name='bias')\n",
    "        y_pred = tf.matmul(w, tf.transpose(x)) + b\n",
    "        \n",
    "    with tf.name_scope('lose') as scope:\n",
    "        loss =tf.reduce_mean(tf.square(y_true - y_pred)) # MSE\n",
    "    \n",
    "    with tf.name_scope('train') as scope:\n",
    "        learning_rate = 0.5\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        train = optimizer.minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for step in range(NUM_STEPS + 1):\n",
    "            sess.run(train, {x: x_data, y_true: y_data})\n",
    "            \n",
    "            if step % 5 == 0: # Every fifth step\n",
    "                print(step, sess.run([w, b]))\n",
    "                wb_.append(sess.run([w, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "w_real = [0.3, 0.5, 0.1]\n",
    "b_real = -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20000\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "x_data = np.random.randn(N, 3)\n",
    "\n",
    "wxb = np.matmul(w_real, x_data.T) + b_real\n",
    "\n",
    "y_data_pre_noise = sigmoid(wxb)\n",
    "y_data = np.random.binomial(1, y_data_pre_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y_pred = tf.sigmoid(y_pred)  \n",
    "loss = y_true * tf.log(y_pred) - (1 -y_true) * tf.log(1 - y_pred)\n",
    "loss = tf.reduce_mean(loss)`\n",
    "\n",
    "#### Equivalent to the above commented code \n",
    "`tf.nn.sigmoid_cross_entropy_with_logits(labels=, logits=)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [array([[ 0.07276371,  0.11800744,  0.02292892]], dtype=float32), 0.45440653])\n",
      "(5, [array([[ 0.07099903,  0.11634681,  0.02178503]], dtype=float32), 0.45349506])\n",
      "(10, [array([[ 0.07099903,  0.11634681,  0.02178503]], dtype=float32), 0.45349506])\n",
      "(15, [array([[ 0.07099903,  0.11634681,  0.02178503]], dtype=float32), 0.45349506])\n",
      "(20, [array([[ 0.07099903,  0.11634681,  0.02178503]], dtype=float32), 0.45349506])\n",
      "(25, [array([[ 0.07099903,  0.11634681,  0.02178503]], dtype=float32), 0.45349506])\n",
      "(30, [array([[ 0.07099903,  0.11634681,  0.02178503]], dtype=float32), 0.45349506])\n",
      "(35, [array([[ 0.07099903,  0.11634681,  0.02178503]], dtype=float32), 0.45349506])\n",
      "(40, [array([[ 0.07099903,  0.11634681,  0.02178503]], dtype=float32), 0.45349506])\n",
      "(45, [array([[ 0.07099903,  0.11634681,  0.02178503]], dtype=float32), 0.45349506])\n",
      "(50, [array([[ 0.07099903,  0.11634681,  0.02178503]], dtype=float32), 0.45349506])\n"
     ]
    }
   ],
   "source": [
    "NUM_STEPS = 50\n",
    "with g.as_default():\n",
    "    with tf.name_scope('loss') as scope:\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "    # Before starting, initialize the variables. We will 'run' this first.\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for step in range(NUM_STEPS):\n",
    "            sess.run(train,{x: x_data, y_true: y_data})\n",
    "#             print(step, 'It is now')\n",
    "            if step % 5 == 0:\n",
    "                print(step, sess.run([w,b]))\n",
    "            wb_.append(sess.run([w,b]))\n",
    "        print(50, sess.run([w,b]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
